 import splitfolders
import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from keras.applications.resnet import ResNet50
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ReduceLROnPlateau
from keras.layers import Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical
import tensorflow as tf
import warnings
warnings.filterwarnings('ignore')

# 이미지 분할
splitfolders.ratio('/Users/gim-yeongmin/Downloads/사업/데이터/Spectrogram',
                   output=('/Users/gim-yeongmin/Downloads/사업/데이터/Spectrogram'), seed=1337, ratio=(0.8, 0.1, 0.1))

# 경로 설정
train_path ='/Users/gim-yeongmin/Downloads/사업/데이터/Spectrogram/train'
test_path ='/Users/gim-yeongmin/Downloads/사업/데이터/Spectrogram/test'
val_path ='/Users/gim-yeongmin/Downloads/사업/데이터/Spectrogram/val'

# 하이퍼파라미터 설정
batch_size = 25
test_batch_size = 32
test_steps = 1
learn_rate = 0.001

# ImageDataGenerator 설정
trgen = ImageDataGenerator(horizontal_flip=True)
tvgen = ImageDataGenerator()

# 데이터 로더 생성
train_generator = trgen.flow_from_directory(directory=train_path, target_size=(224, 224), class_mode='categorical',
                                            color_mode='rgb', shuffle=True, batch_size=batch_size)
test_generator = tvgen.flow_from_directory(directory=test_path, target_size=(224, 224), class_mode='categorical',
                                           color_mode='rgb', shuffle=False, batch_size=test_batch_size)
valid_generator = tvgen.flow_from_directory(directory=val_path, target_size=(224, 224), class_mode='categorical',
                                            color_mode='rgb', shuffle=True, batch_size=batch_size)

import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D

# 입력 이미지의 크기
input_shape = (224, 224, 3)

# 입력 레이어 정의
image_input = Input(shape=input_shape)

# 첫 번째 Convolutional 레이어
x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)

# 두 번째 Convolutional 레이어
x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
x = MaxPooling2D(pool_size=(2, 2))(x)

# 세 번째 Convolutional 레이어
x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
x = MaxPooling2D(pool_size=(2, 2))(x)

# 네 번째 Convolutional 레이어
x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)
x = MaxPooling2D(pool_size=(2, 2))(x)

# 다섯 번째 Convolutional 레이어
x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)
x = MaxPooling2D(pool_size=(2, 2))(x)

# 여섯 번째 Convolutional 레이어
x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)
x = MaxPooling2D(pool_size=(2, 2))(x)

# Flatten 레이어 추가
x = Flatten()(x)

# Fully Connected 레이어 추가
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
output = Dense(17, activation='softmax')(x)  # num_classes는 클래스의 개수에 맞게 설정해야 합니다.

# 새로운 모델 구성
model = Model(inputs=image_input, outputs=output)

# 새로운 모델 컴파일
optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

# 학습
history = model.fit(train_generator, epochs=50, validation_data=valid_generator, verbose=1)

# 모델 저장
model.save("my_model.h5")


from keras.models import load_model
from keras.optimizers import Adam
import librosa
import numpy as np
import tensorflow as tf
import mysql.connector as connector
import traceback
# 모델 불러오기
model = load_model(“all_batch32_dense(224,224).hdf5”, custom_objects={“Adam”: Adam})
# wav 파일 불러오기
filename = ‘N-10_220918_A_1_b_01291_edit.wav’
y, sr = librosa.load(filename)
class_names = ['중량충격음','가구끄는소리','악기','애완동물']
check = [0] * len(class_names)  # 가장 많이 나온 것 판단
n_fft = 2048
hop_length = 512
n_mels = 64
fmin = 20
fmax = 8000
duration = 15
# 이미지화 -> 판단
for j in range(0, len(y)-duration*sr+1, duration*sr):
    y_interval = y[j:j+duration*sr]
    S = librosa.feature.melspectrogram(y=y_interval, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, fmin=fmin, fmax=fmax)
    S_dB = librosa.power_to_db(S, ref=np.max)
    S_dB_norm = (S_dB - np.min(S_dB)) / (np.max(S_dB) - np.min(S_dB)) * 255
    S_dB_norm_resized = tf.image.resize(tf.expand_dims(tf.convert_to_tensor(S_dB_norm), axis=-1), [224, 224])
    S_dB_norm_resized_4d = tf.expand_dims(S_dB_norm_resized, axis=0)
    S_dB_norm_resized_4d = tf.repeat(S_dB_norm_resized_4d, 3, axis=-1).numpy()
    preds = model.predict(S_dB_norm_resized_4d) #판단하는 부분
    check[np.argmax(preds[0])]+=1
# 추론 결과값 출력
result_class = class_names[np.argmax(check)]
print(result_class)

